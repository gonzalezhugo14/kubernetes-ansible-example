{"stderr_lines": ["\t[WARNING FileExisting-crictl]: crictl not found in system path", "Suggestion: go get github.com/kubernetes-incubator/cri-tools/cmd/crictl"], "cmd": ["kubeadm", "init"], "end": "2018-05-16 20:19:31.096488", "failed": false, "stdout": "[init] Using Kubernetes version: v1.10.2\n[init] Using Authorization modes: [Node RBAC]\n[preflight] Running pre-flight checks.\n[preflight] Starting the kubelet service\n[certificates] Generated ca certificate and key.\n[certificates] Generated apiserver certificate and key.\n[certificates] apiserver serving cert is signed for DNS names [k8smaster kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.1.23]\n[certificates] Generated apiserver-kubelet-client certificate and key.\n[certificates] Generated etcd/ca certificate and key.\n[certificates] Generated etcd/server certificate and key.\n[certificates] etcd/server serving cert is signed for DNS names [localhost] and IPs [127.0.0.1]\n[certificates] Generated etcd/peer certificate and key.\n[certificates] etcd/peer serving cert is signed for DNS names [k8smaster] and IPs [192.168.1.23]\n[certificates] Generated etcd/healthcheck-client certificate and key.\n[certificates] Generated apiserver-etcd-client certificate and key.\n[certificates] Generated sa key and public key.\n[certificates] Generated front-proxy-ca certificate and key.\n[certificates] Generated front-proxy-client certificate and key.\n[certificates] Valid certificates and keys now exist in \"/etc/kubernetes/pki\"\n[kubeconfig] Wrote KubeConfig file to disk: \"/etc/kubernetes/admin.conf\"\n[kubeconfig] Wrote KubeConfig file to disk: \"/etc/kubernetes/kubelet.conf\"\n[kubeconfig] Wrote KubeConfig file to disk: \"/etc/kubernetes/controller-manager.conf\"\n[kubeconfig] Wrote KubeConfig file to disk: \"/etc/kubernetes/scheduler.conf\"\n[controlplane] Wrote Static Pod manifest for component kube-apiserver to \"/etc/kubernetes/manifests/kube-apiserver.yaml\"\n[controlplane] Wrote Static Pod manifest for component kube-controller-manager to \"/etc/kubernetes/manifests/kube-controller-manager.yaml\"\n[controlplane] Wrote Static Pod manifest for component kube-scheduler to \"/etc/kubernetes/manifests/kube-scheduler.yaml\"\n[etcd] Wrote Static Pod manifest for a local etcd instance to \"/etc/kubernetes/manifests/etcd.yaml\"\n[init] Waiting for the kubelet to boot up the control plane as Static Pods from directory \"/etc/kubernetes/manifests\".\n[init] This might take a minute or longer if the control plane images have to be pulled.\n[apiclient] All control plane components are healthy after 32.505412 seconds\n[uploadconfig]\u00a0Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace\n[markmaster] Will mark node k8smaster as master by adding a label and a taint\n[markmaster] Master k8smaster tainted and labelled with key/value: node-role.kubernetes.io/master=\"\"\n[bootstraptoken] Using token: lly3h9.jv86bjqgxopr7gal\n[bootstraptoken] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstraptoken] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstraptoken] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[bootstraptoken] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace\n[addons] Applied essential addon: kube-dns\n[addons] Applied essential addon: kube-proxy\n\nYour Kubernetes master has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nYou can now join any number of machines by running the following on each node\nas root:\n\n  kubeadm join 192.168.1.23:6443 --token lly3h9.jv86bjqgxopr7gal --discovery-token-ca-cert-hash sha256:ff09835f64a18ea6d569a6d796b36251dfd438cf062812f69d28369054753d87", "changed": true, "rc": 0, "start": "2018-05-16 20:18:36.355300", "stderr": "\t[WARNING FileExisting-crictl]: crictl not found in system path\nSuggestion: go get github.com/kubernetes-incubator/cri-tools/cmd/crictl", "delta": "0:00:54.741188", "stdout_lines": ["[init] Using Kubernetes version: v1.10.2", "[init] Using Authorization modes: [Node RBAC]", "[preflight] Running pre-flight checks.", "[preflight] Starting the kubelet service", "[certificates] Generated ca certificate and key.", "[certificates] Generated apiserver certificate and key.", "[certificates] apiserver serving cert is signed for DNS names [k8smaster kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.1.23]", "[certificates] Generated apiserver-kubelet-client certificate and key.", "[certificates] Generated etcd/ca certificate and key.", "[certificates] Generated etcd/server certificate and key.", "[certificates] etcd/server serving cert is signed for DNS names [localhost] and IPs [127.0.0.1]", "[certificates] Generated etcd/peer certificate and key.", "[certificates] etcd/peer serving cert is signed for DNS names [k8smaster] and IPs [192.168.1.23]", "[certificates] Generated etcd/healthcheck-client certificate and key.", "[certificates] Generated apiserver-etcd-client certificate and key.", "[certificates] Generated sa key and public key.", "[certificates] Generated front-proxy-ca certificate and key.", "[certificates] Generated front-proxy-client certificate and key.", "[certificates] Valid certificates and keys now exist in \"/etc/kubernetes/pki\"", "[kubeconfig] Wrote KubeConfig file to disk: \"/etc/kubernetes/admin.conf\"", "[kubeconfig] Wrote KubeConfig file to disk: \"/etc/kubernetes/kubelet.conf\"", "[kubeconfig] Wrote KubeConfig file to disk: \"/etc/kubernetes/controller-manager.conf\"", "[kubeconfig] Wrote KubeConfig file to disk: \"/etc/kubernetes/scheduler.conf\"", "[controlplane] Wrote Static Pod manifest for component kube-apiserver to \"/etc/kubernetes/manifests/kube-apiserver.yaml\"", "[controlplane] Wrote Static Pod manifest for component kube-controller-manager to \"/etc/kubernetes/manifests/kube-controller-manager.yaml\"", "[controlplane] Wrote Static Pod manifest for component kube-scheduler to \"/etc/kubernetes/manifests/kube-scheduler.yaml\"", "[etcd] Wrote Static Pod manifest for a local etcd instance to \"/etc/kubernetes/manifests/etcd.yaml\"", "[init] Waiting for the kubelet to boot up the control plane as Static Pods from directory \"/etc/kubernetes/manifests\".", "[init] This might take a minute or longer if the control plane images have to be pulled.", "[apiclient] All control plane components are healthy after 32.505412 seconds", "[uploadconfig]\u00a0Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace", "[markmaster] Will mark node k8smaster as master by adding a label and a taint", "[markmaster] Master k8smaster tainted and labelled with key/value: node-role.kubernetes.io/master=\"\"", "[bootstraptoken] Using token: lly3h9.jv86bjqgxopr7gal", "[bootstraptoken] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials", "[bootstraptoken] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token", "[bootstraptoken] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster", "[bootstraptoken] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace", "[addons] Applied essential addon: kube-dns", "[addons] Applied essential addon: kube-proxy", "", "Your Kubernetes master has initialized successfully!", "", "To start using your cluster, you need to run the following as a regular user:", "", "  mkdir -p $HOME/.kube", "  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config", "  sudo chown $(id -u):$(id -g) $HOME/.kube/config", "", "You should now deploy a pod network to the cluster.", "Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:", "  https://kubernetes.io/docs/concepts/cluster-administration/addons/", "", "You can now join any number of machines by running the following on each node", "as root:", "", "  kubeadm join 192.168.1.23:6443 --token lly3h9.jv86bjqgxopr7gal --discovery-token-ca-cert-hash sha256:ff09835f64a18ea6d569a6d796b36251dfd438cf062812f69d28369054753d87"]}